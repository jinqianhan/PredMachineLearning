---
title: "HCMachineLearningPA"
author: "Hank"
date: "December 27, 2015"
output: html_document
---

We first load the appropriate libraries and data set
```{r}
library(caret); library(ggplot2); library(rpart); library(parallel); library(randomForest)
train <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", header=TRUE)
test <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", header=TRUE)
```

Exploratory data analysis
```{r, results="hide"}
str(train)
summary(train)
head(train)
```

Cleaning and Processing data
Remove columns with factor variables and NAs, as it will slow the tree building. Remove first 7 columns as they are timers and not from accelerometer
```{r}
training <- train[, colSums(is.na(train)) == 0]
training <- training[8:ncol(training)]
classe <- training[,ncol(training)]
training <- training[, !sapply(training, is.factor)]
training <- cbind(training, classe)
```

Set seed to 314
Opt to use k-fold sampling for cross validation on training set becuse 19622 observation is a sufficient sample size to split the data. Repeated random subsampling may leave out some of the data. Choose to create 5 folds

Use randomforest algorithm to run training model predictions
```{r}
set.seed(314)
folds <- createFolds(y=train$classe,k=10,
                             list=TRUE,returnTrain=TRUE)
folds[[1]][1:10]
```

```{r, cache=TRUE}
set.seed(314)
tc <- trainControl(method = "oob", number = 5, p = 0.75,  allowParallel = TRUE)
modelfit <- train(classe ~., method = "rf", data = training, trControl = tc, prox = TRUE)

#ttrain <- training[folds[[1]],]
#ttest <- training[-folds[[1]],]
#fit <- randomForest(classe ~ ., data=ttrain, prox=TRUE, ntree=200)
pred <- predict(modelfit,test)
table(pred,test$classe)
answers <- pred

pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(answers)
```
